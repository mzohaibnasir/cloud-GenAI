{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/cloud-GenAI/blob/main/02_End_to_End_usecase_using_AWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lifecycle of GenAI project\n",
        "\n",
        "    [deine usecase] ->\n",
        "    [choose right model( foundation or custom] ->\n",
        "    [to solve this task you can (i) prompt engineering (ii) finetuning (iii) Training with human feedback- Alligning]->\n",
        "    [Evaluation]->\n",
        "    [Metrics]->\n",
        "\n",
        "Deployment:\n",
        "\n",
        "    [Deployment]->\n",
        "    [application intgration]->\n",
        "    [Optimize and deploy model for inferencing usingtechniques like groq(LLMOps)] or [Build LLM-powered applications]->\n",
        "\n",
        "adapt and allign modeules: step(iii +iv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Two categories\n",
        "\n",
        "1. Foundation model i.e. Llama2, openai\n",
        "   1. we can fine tune our FM to suit our custom task\n",
        "2. Custom models: building LLM from scratch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project scope and steps\n",
        "\n",
        "1. we are doing blog generation\n",
        "\n",
        "2. we will be creating an API endpoint using API Gateway\n",
        "3. hitting API will trigger lambda function\n",
        "4. lambda will be interacting with AWS bedrock API\n",
        "   1. our all Foundation Models are available in bedrock\n",
        "5. we'll bw saving response in s3 text as .txt file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## lambda function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6RmG8qtUmET"
      },
      "outputs": [],
      "source": [
        "# to get lateset boto3 version\n",
        "\n",
        "# pip install boto3 -t python/\n",
        "# zip that folder and add it as boto3 layer\n",
        "\n",
        "import boto3\n",
        "import botocore.config\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# boto3 to invoke FMs\n",
        "\n",
        "\n",
        "s3_bucket = \"awsbedrockbucketc1\"\n",
        "\n",
        "\n",
        "# blog generation\n",
        "def blog_generation_using_bedrock(blogTopic: str) -> str:\n",
        "    prompt = f\"\"\"Write a 200 words blog on the topic { blogTopic}\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt = f\"\"\"<s>[INST]Human: Write a 200 words blog on the topic { blogTopic}\n",
        "    #  Assistant:[/INST]\"\"\" # for llama\n",
        "\n",
        "    body = {\n",
        "        \"inputText\": prompt,\n",
        "        \"textGenerationConfig\": {\n",
        "            \"maxTokenCount\": 512,\n",
        "            \"stopSequences\": [],\n",
        "            \"temperature\": 0.5,\n",
        "            \"topP\": 1,\n",
        "        },\n",
        "    }\n",
        "    accept = \"application/json\"\n",
        "    content_type = \"application/json\"\n",
        "\n",
        "    try:\n",
        "        bedrock = boto3.client(\n",
        "            \"bedrock-runtime\",\n",
        "            region_name=\"ap-southeast-2\",\n",
        "            config=botocore.config.Config(\n",
        "                read_timeout=300, retries={\"max_attempts\": 3}\n",
        "            ),\n",
        "        )\n",
        "        response = bedrock.invoke_model(\n",
        "            body=json.dumps(body),\n",
        "            modelId=\"amazon.titan-text-lite-v1\",\n",
        "            accept=accept,\n",
        "            contentType=content_type,\n",
        "        )\n",
        "        response_content = response.get(\"body\").read()\n",
        "        response_data = json.loads(response_content)\n",
        "        print(response_data)\n",
        "        blog_details = response_data[\"results\"][0][\"outputText\"]\n",
        "        print(blog_details)\n",
        "\n",
        "        return blog_details\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating the blog: {e}\")\n",
        "        # return \"xxxxxxxxxx\"\n",
        "\n",
        "\n",
        "def save_blog_details_in_s3(s3_key, s3_bucket, generate_blog):\n",
        "    s3 = boto3.client(\"s3\")\n",
        "\n",
        "    try:\n",
        "        s3.put_object(Bucket=s3_bucket, Key=s3_key, Body=generate_blog)\n",
        "        print(\"text saved to s3\")\n",
        "    except Exception as e:\n",
        "        print(\"Error saving!: save_blog_details_in_s3()\")\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    print(f\"event: {event}\")\n",
        "    body = json.loads(event[\"body\"])\n",
        "    print(f\"body: {body}\")\n",
        "    blogtopic = body[\"blog_topic\"]\n",
        "    print(f\"blogtopic: {blogtopic}\")\n",
        "\n",
        "    generate_blog = blog_generation_using_bedrock(\n",
        "        blogTopic=blogtopic,\n",
        "    )\n",
        "    if generate_blog:\n",
        "        current_time = datetime.now().strftime(\"%H%M%S\")\n",
        "        s3_key = f\"blog_ouput/{current_time}.txt\"\n",
        "        # s3_bucket = \"awsbedrockbucketc1\"\n",
        "        save_blog_details_in_s3(\n",
        "            s3_key=s3_key, s3_bucket=s3_bucket, generate_blog=generate_blog\n",
        "        )\n",
        "    else:\n",
        "        print(\"No blog was generated.\")\n",
        "\n",
        "    return {\"statusCode\": 200, \"body\": json.dumps(\"Blog generation done\")}\n",
        "\n",
        "\n",
        "##################################3\n",
        "{\n",
        "    \"modelId\": \"amazon.titan-text-lite-v1\",\n",
        "    \"contentType\": \"application/json\",\n",
        "    \"accept\": \"application/json\",\n",
        "    \"body\": '{\"inputText\":\"this is where you place your input text\",\"textGenerationConfig\":{\"maxTokenCount\":4096,\"stopSequences\":[],\"temperature\":0,\"topP\":1}}',\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOG8O6WN96So5IkEa00yJ3X",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
